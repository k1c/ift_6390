{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "The method SVM.fit uses the code you wrote above to train the SVM. After each epoch (one pass through the training set), SVM.fit computes the training loss, the training accuracy, the test loss, and the test accuracy.\n",
    "    \n",
    "Plot the value of these four quantities for every epoch for C = 0.1, 1, 30, 50. \n",
    "\n",
    "Use 200 epochs, a learning rate of 0.001, and a minibatch size of 5000.\n",
    "    \n",
    "You should have four plots: one for each quantity, with the curves for all four values of C. \n",
    "Include these four plots in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self,eta, C, niter, batch_size, verbose):\n",
    "        self.eta = eta; self.C = C; self.niter = niter; self.batch_size = batch_size; self.verbose = verbose\n",
    "\n",
    "#TODO check edges cases for m (can we assume that the max label number is smaller than m?)\n",
    "    def make_one_versus_all_labels(self, y, m):\n",
    "        \"\"\"\n",
    "\ty : numpy array of shape (n,)\n",
    "\tm : int (in this homework, m will be 10)\n",
    "\treturns : numpy array of shape (n,m)\n",
    "\t\"\"\"\n",
    "        ova = np.full((y.shape[0], m), -1)\n",
    "        for i, row in enumerate(ova):\n",
    "            row[y[i]] = 1\n",
    "        return ova\n",
    "\n",
    "    def compute_loss(self, x, y):\n",
    "        \"\"\"underunderunder\n",
    "\tx : numpy array of shape (minibatch size, 401)\n",
    "\ty : numpy array of shape (minibatch size, 10)\n",
    "\treturns : float\n",
    "\t\"\"\"\n",
    "        scores = x.dot(self.w)\n",
    "        margins = np.maximum(0, 1 - np.multiply(scores, y))\n",
    "        loss = np.mean(np.sum(margins, axis=1))\n",
    "        loss = self.C * loss\n",
    "        # Computes de regularization term\n",
    "        loss += 0.5 * np.sum(np.linalg.norm(self.w, ord=2, axis=0))\n",
    "        return loss\n",
    "\n",
    "    def compute_gradient(self, x, y):\n",
    "        \"\"\"\n",
    "\tx : numpy array of shape (minibatch size, 401)\n",
    "\ty : numpy array of shape (minibatch size, 10)\n",
    "\treturns : numpy array of shape (401, 10)\n",
    "\t\"\"\"\n",
    "        scores = x.dot(self.w)\n",
    "        active = (np.multiply(scores, y) < 1).astype(float)\n",
    "        grad = np.dot(-x.T, np.multiply(y, active))\n",
    "        grad = 2 * self.C * grad / y.shape[0]\n",
    "        # Regularization term\n",
    "        grad += self.w\n",
    "        return grad\n",
    "\n",
    "    # Batcher function\n",
    "    def minibatch(self, iterable1, iterable2, size=1):\n",
    "        l = len(iterable1)\n",
    "        n = size\n",
    "        for ndx in range(0, l, n):\n",
    "            index2 = min(ndx + n, l)\n",
    "            yield iterable1[ndx: index2], iterable2[ndx: index2]\n",
    "\n",
    "    def infer(self, x):\n",
    "        \"\"\"\n",
    "\tx : numpy array of shape (number of examples to infer, 401)\n",
    "\treturns : numpy array of shape (number of examples to infer, 10)\n",
    "\t\"\"\"\n",
    "        y = x.dot(self.w)\n",
    "        y_ova = -1 * np.ones(y.shape)\n",
    "        y_ova[:, np.argmax(y, axis=1)] = 1\n",
    "        return y_ova\n",
    "\n",
    "    def compute_accuracy(self, y_inferred, y):\n",
    "        \"\"\"\n",
    "\ty_inferred : numpy array of shape (number of examples, 10)\n",
    "\ty : numpy array of shape (number of examples, 10)\n",
    "\treturns : float\n",
    "\t\"\"\"\n",
    "        return np.sum(np.all(y == y_inferred, axis=1).astype(float)) / y.shape[0]\n",
    "\n",
    "    def fit(self, x_train, y_train, x_test, y_test):\n",
    "        \"\"\"\n",
    "        x_train : numpy array of shape (number of training examples, 401)\n",
    "        y_train : numpy array of shape (number of training examples, 10)\n",
    "        x_test : numpy array of shape (number of training examples, 401)\n",
    "        y_test : numpy array of shape (number of training examples, 10)\n",
    "        returns : float, float, float, float\n",
    "        \"\"\"\n",
    "        self.num_features = x_train.shape[1]\n",
    "        self.m = y_train.max() + 1\n",
    "        y_train = self.make_one_versus_all_labels(y_train, self.m)\n",
    "        y_test = self.make_one_versus_all_labels(y_test, self.m)\n",
    "        self.w = np.zeros([self.num_features, self.m])\n",
    "        \n",
    "        train_loss_epoch = list()\n",
    "        train_acc_epoch = list()\n",
    "        test_loss_epoch = list()\n",
    "        test_acc_epoch = list()\n",
    "        iterations = list()\n",
    "        \n",
    "        for iteration in range(self.niter):\n",
    "            # Train one pass through the training set\n",
    "            for x, y in self.minibatch(x_train, y_train, size=self.batch_size):\n",
    "                grad = self.compute_gradient(x, y)\n",
    "                self.w -= self.eta * grad\n",
    "\n",
    "            # Measure loss and accuracy on training set\n",
    "            train_loss = self.compute_loss(x_train, y_train)\n",
    "            y_inferred = self.infer(x_train)\n",
    "            train_accuracy = self.compute_accuracy(y_inferred, y_train)\n",
    "\n",
    "            # Measure loss and accuracy on test set\n",
    "            test_loss = self.compute_loss(x_test, y_test)\n",
    "            y_inferred = self.infer(x_test)\n",
    "            test_accuracy = self.compute_accuracy(y_inferred, y_test)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"Iteration %d:\" % iteration)\n",
    "                print(\"Train accuracy: %f\" % train_accuracy)\n",
    "                print(\"Train loss: %f\" % train_loss)\n",
    "                print(\"Test accuracy: %f\" % test_accuracy)\n",
    "                print(\"Test loss: %f\" % test_loss)\n",
    "                print(\"\")\n",
    "            \n",
    "            train_loss_epoch.append(train_loss)\n",
    "            train_acc_epoch.append(train_accuracy)\n",
    "            test_loss_epoch.append(test_loss)\n",
    "            test_acc_epoch.append(test_accuracy)\n",
    "            iterations.append(iteration)\n",
    "            \n",
    "        return train_loss_epoch, train_acc_epoch, test_loss_epoch, test_acc_epoch, iterations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the data files\n",
    "    print(\"Loading data...\")\n",
    "    x_train = np.load(\"train_features.npy\")\n",
    "    x_test = np.load(\"test_features.npy\")\n",
    "    y_train = np.load(\"train_labels.npy\")\n",
    "    y_test = np.load(\"test_labels.npy\")\n",
    "     \n",
    "    def plot_train_losses(train_losses,iterations):\n",
    "        plt.plot(iterations,train_losses[0],label=\"C = 0.1\")\n",
    "        plt.plot(iterations,train_losses[1],label=\"C = 1\")\n",
    "        plt.plot(iterations,train_losses[2],label=\"C = 30\")\n",
    "        plt.plot(iterations,train_losses[3],label=\"C = 50\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Training Loss per Epoch\")\n",
    "        plt.xlabel('Number of Epoch')\n",
    "        plt.ylabel('Training Loss')\n",
    "        #plt.show()\n",
    "        plt.savefig('Training Loss per Epoch.png', bbox_inches='tight')\n",
    "    \n",
    "    def plot_train_accs(train_accs,iterations):\n",
    "        plt.plot(iterations,train_accs[0],label=\"C = 0.1\")\n",
    "        plt.plot(iterations,train_accs[1],label=\"C = 1\")\n",
    "        plt.plot(iterations,train_accs[2],label=\"C = 30\")\n",
    "        plt.plot(iterations,train_accs[3],label=\"C = 50\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Training Accuracies per Epoch\")\n",
    "        plt.xlabel('Number of Epoch')\n",
    "        plt.ylabel('Training Accuracy')\n",
    "        #plt.show()\n",
    "        plt.savefig('Training Accuracies per Epoch.png', bbox_inches='tight')\n",
    "        \n",
    "    def plot_test_losses(test_losses,iterations):\n",
    "        plt.plot(iterations,test_losses[0],label=\"C = 0.1\")\n",
    "        plt.plot(iterations,test_losses[1],label=\"C = 1\")\n",
    "        plt.plot(iterations,test_losses[2],label=\"C = 30\")\n",
    "        plt.plot(iterations,test_losses[3],label=\"C = 50\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Testing Loss per Epoch\")\n",
    "        plt.xlabel('Number of Epoch')\n",
    "        plt.ylabel('Testing Loss')\n",
    "        #plt.show()\n",
    "        plt.savefig('Testing Loss per Epoch.png', bbox_inches='tight')\n",
    "        \n",
    "    def plot_test_accs(test_accs,iterations):\n",
    "        plt.plot(iterations,test_accs[0],label=\"C = 0.1\")\n",
    "        plt.plot(iterations,test_accs[1],label=\"C = 1\")\n",
    "        plt.plot(iterations,test_accs[2],label=\"C = 30\")\n",
    "        plt.plot(iterations,test_accs[3],label=\"C = 50\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Testing Accuracies per Epoch\")\n",
    "        plt.xlabel('Number of Epoch')\n",
    "        plt.ylabel('Testing Accuracy')\n",
    "        #plt.show()\n",
    "        plt.savefig('Testing Accuracies per Epoch.png', bbox_inches='tight')\n",
    "    \n",
    "    C = [0.1, 1, 30, 50]\n",
    "    \n",
    "    EPOCH = 200\n",
    "    \n",
    "    train_losses = list()\n",
    "    train_acc = list()\n",
    "    test_losses = list()\n",
    "    test_acc = list()\n",
    "    \n",
    "    for c in C:\n",
    "        svm = SVM(eta=0.001, C=c, niter=EPOCH, batch_size=5000, verbose=False)\n",
    "        # to compute the gradient or loss before training, do the following:\n",
    "        y_train_ova = svm.make_one_versus_all_labels(y_train, 10) # one-versus-all labels\n",
    "        svm.w = np.zeros([401, 10])\n",
    "        grad = svm.compute_gradient(x_train, y_train_ova)\n",
    "        loss = svm.compute_loss(x_train, y_train_ova)\n",
    "\n",
    "        train_loss_epoch, train_acc_epoch, test_loss_epoch, test_acc_epoch, iterations = svm.fit(x_train, y_train, x_test, y_test)\n",
    "        \n",
    "        train_losses.append(train_loss_epoch)\n",
    "        train_acc.append(train_acc_epoch)\n",
    "        test_losses.append(test_loss_epoch)\n",
    "        test_acc.append(test_acc_epoch)\n",
    "    \n",
    "    plot_train_losses(train_losses,iterations)\n",
    "    plot_train_accs(train_acc,iterations)\n",
    "    plot_test_losses(test_losses,iterations)\n",
    "    plot_test_accs(test_acc,iterations)\n",
    "    \n",
    "\n",
    "    # to infer after training, do the following:\n",
    "    #y_inferred = svm.infer(x_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
